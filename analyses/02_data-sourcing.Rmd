---
title: "SCORE: Siedner et al. (2020) replication"
subtitle: "Data sourcing"
author: "Radoslaw Panczak"
date: "`r format(Sys.time(), '%d %B, %Y')`"
mainfont: DejaVu Sans
output: 
  html_document: 
    toc: true
    toc_depth: 4
    toc_float: true
    number_sections: true
    theme: united 
    highlight: pygments 
editor_options: 
  chunk_output_type: console
---

<!-- ------------------------------------------------------------ --> 
<!-- ------------------------------------------------------------ --> 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                      fig.width=8, fig.height=6, dpi=300, 
                      out.width="800px", out.height="600px")

knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

options(scipen=999)
set.seed(12345)

library(pacman) 
p_load(tidyverse, readxl, rvest, tabulizer, 
       janitor, sjmisc, sjPlot, skimr,
       stringr, scales, kableExtra)
```

# Timing of state's measures

Data extracted from the table in supplement.

```{r}
# page 4 needs headers
measures_4 <- extract_tables("data-raw/supplement/2020.04.03.20052373-1.pdf",
                             pages = 4, guess = TRUE, 
                             output = "data.frame") %>% 
  purrr::pluck(1) %>% 
  clean_names() %>% 
  filter(state != "") %>% 
  select(-source_s)

# some column drama
measures_8 <- extract_tables("data-raw/supplement/2020.04.03.20052373-1.pdf",
                             pages = 8, guess = FALSE, 
                             output = "data.frame") %>% 
  purrr::pluck(1) %>% 
  clean_names() %>% 
  filter(x != "") %>% 
  select(- x_7) %>% 
  mutate(x_6 = "")

names(measures_8) <- names(measures_4)

# these at least are consistent
for (page in c(5:7, 9:10)){
  
  temp  <- extract_tables("data-raw/supplement/2020.04.03.20052373-1.pdf",
                          pages = page, guess = FALSE, 
                          output = "data.frame") %>% 
    purrr::pluck(1) %>% 
    clean_names() %>% 
    filter(x != "") %>% 
    select(-x_7, -x_8)
  
  names(temp) <- names(measures_4)
  
  if (page == 5) {
    measures_5_10 <- temp
  } else {
    measures_5_10 <- bind_rows(measures_5_10, temp)
  }
}

rm(temp, page)

# another drama
measures_11 <- extract_tables("data-raw/supplement/2020.04.03.20052373-1.pdf",
                              pages = 11, guess = FALSE, 
                              output = "data.frame") %>% 
  purrr::pluck(1) %>% 
  clean_names() %>% 
  filter(x != "") %>% 
  select(-x_6, -x_7) %>% 
  filter(word(x, 1) != "Notes:") %>% 
  filter(word(x, 1) != "of") %>% 
  mutate(state = word(x, end = -2),
         date = word(x, start = -1)) %>% 
  select(-x) %>% 
  relocate(state, date)

names(measures_11) <- names(measures_4)

# all together
measures <- bind_rows(measures_4, 
                      measures_5_10,
                      measures_8, 
                      measures_11) %>% 
  pivot_longer(cols = a:e,
               names_to = "measure_short",
               values_to = "present") %>% 
  filter(present != "") %>% 
  select(-present) %>% 
  mutate(date = as.Date(date, format = "%m/%d/%y")) %>% 
  mutate(
    measure = case_when(
      measure_short == "a" ~ "closure of schools",
      measure_short == "b" ~ "closure of workplaces",
      measure_short == "c" ~ "cancellation of public events",
      measure_short == "d" ~ "restrictions on internal movement",
      measure_short == "e" ~ "closure of state borders"
    )) %>% 
  filter(state != "Puerto Rico") %>% 
  arrange(state, date) %>% 
  as_tibble()
```

Prepared dataset consists of `r number(nrow(measures))` records of `r number(length(unique(measures$state)))` states with measures implemented between `r min(measures$date)` to `r max(measures$date)`. The dataset is in long format. The data for Puerto Rico were excluded since the preprint states that analyses were conducted for 50 states plus DC.

```{r}
str(measures)
```

Frequency of first measure

```{r}
# frq(measures, measure, sort.frq = "desc")
# plot_frq(measures, measure, coord.flip = TRUE)

# frq(measures, state)
# plot_frq(measures, state, coord.flip = TRUE)

measures %>% 
  filter(date >= as.Date("2020-03-10") & date<= as.Date("2020-03-27")) %>% 
  group_by(state) %>% 
  arrange(date) %>% 
  filter(row_number() == 1) %>% 
  ungroup() %>% 
  plot_frq(measure)
```

```{r}
write_rds(measures, "data/supplement/measures.Rds")
write_csv(measures, "data/supplement/measures.csv")

rm(measures_4, measures_5_10, measures_8, measures_11)
```

# NYT Covid-19 data

The New York Times' [Coronavirus (Covid-19) Data in the United States](https://github.com/nytimes/covid-19-data/) repository containing 

> a series of data files with cumulative counts of coronavirus cases in the United States, at the state and county level, over time.

```{r}
urlfile="https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv"

nyt_raw <- read_csv(url(urlfile)) %>% 
  as_tibble()

# sjmisc::frq(nyt_raw, state)

write_rds(nyt_raw, "data-raw/nyt/nyt_raw.Rds")
write_csv(nyt_raw, "data-raw/nyt/nyt_raw.csv")
```

Raw dataset downloaded on `r format(Sys.time(), '%d %B, %Y')` consists of `r number(nrow(nyt_raw), big.mark = ",")` records of `r number(length(unique(nyt_raw$state)))` states from `r min(nyt_raw$date)` to `r max(nyt_raw$date)`. 

Data are first limited to the 50 states plus DC - that was achieved by excluding `fips` codes `66, 69, 72, 78` for Guam, Northern Mariana Islands, Puerto Rico and Virgin Islands.

```{r}
nyt_raw %>% 
  filter(fips %in% c(66, 69, 72, 78)) %>% 
  group_by(state, fips) %>% 
  summarise(records = n(),
            cases = sum(cases),
            deaths = sum(deaths)) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", full_width = FALSE))
```

Next, data is limited to match the time frame of the analysis ie. until `2020-03-30`. Next, logarithms and their difference are calculated. Finally only days when cumulative number of cases reached 30 are kept in the dataset.

```{r}
nyt <- nyt_raw %>%
  filter(!fips %in% c(66, 69, 72, 78)) %>% 
  select(-fips, -deaths) %>%
  filter(date <= as.Date("2020-03-30")) %>%
  arrange(state, date) %>%
  group_by(state) %>%
  mutate(cases_perc = ((cases - lag(cases))/ lag(cases)) *100,
         cases_daybefore = lag(cases)) %>%
  ungroup() %>%
  mutate(cases_ln = log(cases),
         cases_daybefore_ln = log(cases_daybefore),
         log_dif = cases_ln - cases_daybefore_ln) %>%
  filter(cases >= 30) %>% 
  arrange(state, date) %>% 
  as_tibble()
```

Prepared dataset consists of `r number(nrow(nyt), big.mark = ",")` records of `r number(length(unique(nyt$state)))` states from `r min(nyt$date)` to `r max(nyt$date)` period. 

```{r}
write_rds(nyt, "data/nyt/nyt.Rds")
write_csv(nyt, "data/nyt/nyt.csv")
rm(nyt_raw)
```

Frequency of records by state:

```{r}
# length(unique(nyt$state))
# frq(nyt, state) 
nyt %>% 
  group_by(state) %>% 
  summarize(records = n()) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", full_width = FALSE))
```

And by date:

```{r}
# length(unique(nyt$date))
# frq(nyt, date)
nyt %>% 
  group_by(date) %>% 
  summarize(records = n()) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", full_width = FALSE))
```

Missing and `Inf` data situation

```{r}
sapply(nyt, function(x) sum(is.na(x)))
sapply(nyt, function(x) sum(is.nan(x)))
sapply(nyt, function(x) sum(is.infinite(x)))
```

```{r eval=FALSE, include=FALSE}
# (missing <- anti_join(
#    as_tibble(unique(measures$state)), 
#    as_tibble(unique(nyt$state))
# ))
```

# Link of measures & cases datasets 

## First measure

```{r}
measures_first <- measures %>% 
  select(-measure_short) %>% 
  group_by(state) %>% 
  arrange(date) %>% 
  slice(1) %>% 
  rename(date_first = date) %>% 
  ungroup()

measures_first %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", full_width = FALSE))

nyt_first <- left_join(nyt, measures_first) %>% 
  mutate(time_to_intervention = as.numeric(date - date_first),
         post_intervention = ifelse(time_to_intervention <= 3, 0, 1)) %>% 
  arrange(state, time_to_intervention) 
```

Prepared dataset consists of `r number(nrow(nyt_first), big.mark = ",")` records of `r number(length(unique(nyt_first$state)))` states from `r min(nyt_first$date)` to `r max(nyt_first$date)` period. 

```{r}
str(nyt_first)
```

Example of first state:  

```{r}
nyt_first %>% 
  filter(state == "Alabama") %>% 
  select(date, state, log_dif, 
         date_first, time_to_intervention, post_intervention) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", full_width = FALSE))
```

Median & IQR size of epidemic when measure was implemented

```{r}
nyt_first %>% 
  filter(date == date_first) %>% 
  summarise(median = median(cases),
            p25 = quantile(cases, prob = 0.25),
            p75 = quantile(cases, prob = 0.75))
```

Mean size of epidemic growth

```{r}
nyt_first %>% 
  filter(date == date_first) %>% 
  summarise(mean = mean(cases_perc))
```

```{r}
write_rds(nyt_first, "data/nyt_first.Rds")
write_csv(nyt_first, "data/nyt_first.csv")
```

## Lockdown

Not all states implemented that!

```{r}
measures_lockdown <- measures %>% 
  filter(measure == "restrictions on internal movement") %>% 
  select(-measure_short) %>% 
  rename(date_lockdown = date)

measures_lockdown %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", full_width = FALSE))

nyt_lockdown <- left_join(nyt, measures_lockdown) %>% 
  mutate(date_lockdown_filled = if_else(is.na(date_lockdown), as.Date("2020-03-30"), date_lockdown)) %>% 
  mutate(time_to_lockdown = as.numeric(date - date_lockdown_filled),
         post_intervention = ifelse(time_to_lockdown <= 3, 0, 1)) %>% 
  arrange(state, time_to_lockdown) 
```

Prepared dataset consists of `r number(nrow(nyt_lockdown), big.mark = ",")` records of `r number(length(unique(nyt_lockdown$state)))` states from `r min(nyt_lockdown$date)` to `r max(nyt_lockdown$date)` period. 

```{r}
str(nyt_first)
```

Example of one state:  

```{r}
nyt_lockdown %>% 
  filter(state == "Connecticut") %>% 
  select(date, state, log_dif, 
         date_lockdown_filled, time_to_lockdown, post_intervention) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", full_width = FALSE))
```

Median & IQR size of epidemic when measure was implemented

```{r}
nyt_lockdown %>% 
  filter(time_to_lockdown  == 0) %>% 
  summarise(median = median(cases),
            p25 = quantile(cases, prob = 0.25),
            p75 = quantile(cases, prob = 0.75))
```

Mean size of epidemic growth

```{r}
nyt_lockdown %>% 
  filter(time_to_lockdown  == 0) %>% 
  summarise(mean = mean(cases_perc))
```

```{r}
write_rds(nyt_lockdown, "data/nyt_lockdown.Rds")
write_csv(nyt_lockdown, "data/nyt_lockdown.csv")
```

# Pop density

## Numerator

Data comes from *State Population Totals and Components of Change: 2010-2019* [website](https://www.census.gov/data/tables/time-series/demo/popest/2010s-state-total.html#par_textimage_1574439295) of the US Census Bureau.

Specifically dataset is extracted from the spreadsheet `Annual Estimates of the Resident Population for the United States, Regions, States, and Puerto Rico: April 1, 2010 to July 1, 2019 (NST-EST2019-01)` fount in the section *Population, Population Change, and Estimated Components of Population Change: April 1, 2010 to July 1, 2019 (NST-EST2019-alldata)*.  

```{r}
population <- read_excel("data-raw/census/nst-est2019-01.xlsx", 
                         skip = 3) %>% 
  clean_names() %>% 
  remove_empty() %>% 
  rename(state = x1,
         pop_2019 = x2019) %>% 
  select(state, pop_2019) %>% 
  filter(! state %in% c("United States", "Northeast", "Midwest", "South", "West"),
         !is.na(pop_2019)) %>% 
  mutate(state = str_replace(state, fixed("."), "")) %>% 
  as_tibble()

population %>% 
  slice(1:5) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", full_width = FALSE))

write_rds(population, "data/census/population.Rds")
write_csv(population, "data/census/population.csv")
```

## Denominator

Data comes from *State Area Measurements and Internal Point Coordinates* [website](https://www.census.gov/geographies/reference-files/2010/geo/state-area.html) of the US Census Bureau. No download was avaialble so table was scraped using `rvest` package. 

```{r}
p_load(rvest)

webpage <- read_html("https://www.census.gov/geographies/reference-files/2010/geo/state-area.html")

# html_nodes(webpage, "table")

area <- webpage %>%
  html_nodes("table") %>%
  .[1] %>%
  html_table(fill = TRUE) %>%
  .[[1]] %>% 
  clean_names() %>% 
  remove_empty() %>% 
  as_tibble() %>% 
  rename(state = state_and_other_areas2) %>% 
  filter(state != "State and other areas2",
         state != "Total3", 
         state != "United States4",
         state != "") %>% 
  select(state, total_area, total_area_2, land_area1, land_area1_2) %>% 
  rename(total_area_km = total_area,
         total_area_mi = total_area_2,
         land_area_km = land_area1,
         land_area_mi = land_area1_2) %>% 
  as_tibble()

area %>% 
  slice(1:5) %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover", full_width = FALSE))

write_rds(area, "data/census/area.Rds")
write_csv(area, "data/census/area.csv")
```
